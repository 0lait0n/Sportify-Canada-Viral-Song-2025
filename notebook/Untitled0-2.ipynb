{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QRWOFgsnHuUQ",
        "outputId": "888e35c9-4265-495e-b5a5-cfe243ce8a32"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "cannot assign to expression (ipython-input-3057435759.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3057435759.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for SQL & Power BI\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression\n"
          ]
        }
      ],
      "source": [
        " for SQL & Power BI\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path(\"/content/data/cleaned_viral_canada_textdates.xlsx\")\n",
        "\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "print(\"Dataset Loaded.\")\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "df.columns = (\n",
        "    df.columns.str.lower()\n",
        "              .str.strip()\n",
        "              .str.replace(\" \", \"_\")\n",
        ")\n",
        "\n",
        "date_cols = [\"date\", \"chart_date\", \"ref_date\"]\n",
        "for col in date_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
        "        break\n",
        "\n",
        "\n",
        "numeric_cols = [\"rank\", \"previous_rank\", \"peak_rank\", \"days_on_chart\"]\n",
        "for col in numeric_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Cleaning complete.\")\n",
        "\n",
        "\n",
        "if \"date\" in df.columns:\n",
        "    df[\"year\"] = df[\"date\"].dt.year\n",
        "    df[\"month\"] = df[\"date\"].dt.month\n",
        "    df[\"week\"] = df[\"date\"].dt.isocalendar().week\n",
        "    df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
        "\n",
        "print(\"Feature engineering done.\")\n",
        "\n",
        "\n",
        "\n",
        "if \"artist_names\" in df.columns and \"days_on_chart\" in df.columns:\n",
        "    artist_longevity = (\n",
        "        df.groupby(\"artist_names\", as_index=False)[\"days_on_chart\"]\n",
        "          .sum()\n",
        "          .sort_values(\"days_on_chart\", ascending=False)\n",
        "    )\n",
        "\n",
        "    artist_longevity.to_csv(\"../data/artist_longevity_summary.csv\", index=False)\n",
        "    print(\"Saved: artist_longevity_summary.csv\")\n",
        "\n",
        "\n",
        "\n",
        "if \"source\" in df.columns and \"rank\" in df.columns:\n",
        "    label_counts = (\n",
        "        df.groupby(\"source\", as_index=False)[\"rank\"]\n",
        "          .count()\n",
        "          .rename(columns={\"rank\": \"total_chart_entries\"})\n",
        "          .sort_values(\"total_chart_entries\", ascending=False)\n",
        "    )\n",
        "\n",
        "    label_counts.to_csv(\"../data/label_chart_entries_summary.csv\", index=False)\n",
        "    print(\"Saved: label_chart_entries_summary.csv\")\n",
        "\n",
        "\n",
        "\n",
        "if all(col in df.columns for col in [\"track_name\", \"peak_rank\", \"previous_rank\"]):\n",
        "    momentum = (\n",
        "        df.groupby(\"track_name\", as_index=False)[[\"peak_rank\", \"previous_rank\"]]\n",
        "          .sum()\n",
        "          .sort_values(\"peak_rank\", ascending=True)\n",
        "    )\n",
        "\n",
        "    momentum.to_csv(\"../data/rank_momentum_summary.csv\", index=False)\n",
        "    print(\"Saved: rank_momentum_summary.csv\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nPython Analysis Completed Successfully.\")"
      ]
    }
  ]
}